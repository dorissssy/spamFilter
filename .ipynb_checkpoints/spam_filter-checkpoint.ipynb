{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lingemails = pd.read_csv(\"lingspam-emails.csv.bz2\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>False</td>\n",
       "      <td>8-1064msg1.txt</td>\n",
       "      <td>Subject: re : 8 . 1044 , disc : grammar in sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>False</td>\n",
       "      <td>5-1434msg1.txt</td>\n",
       "      <td>Subject: linguist / phonetic request for infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>False</td>\n",
       "      <td>6-189msg2.txt</td>\n",
       "      <td>Subject: 6 . 136 language and species  just a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>False</td>\n",
       "      <td>6-203msg1.txt</td>\n",
       "      <td>Subject: endangered languages  january and ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>False</td>\n",
       "      <td>6-197msg3.txt</td>\n",
       "      <td>Subject: summer opportunities  hey ! does anyo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam           files                                            message\n",
       "2474  False  8-1064msg1.txt  Subject: re : 8 . 1044 , disc : grammar in sch...\n",
       "700   False  5-1434msg1.txt  Subject: linguist / phonetic request for infor...\n",
       "1056  False   6-189msg2.txt  Subject: 6 . 136 language and species  just a ...\n",
       "1074  False   6-203msg1.txt  Subject: endangered languages  january and ear...\n",
       "1063  False   6-197msg3.txt  Subject: summer opportunities  hey ! does anyo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingemails.sample(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam       0\n",
       "files      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingemails.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data and get the DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(lingemails.message)\n",
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60925"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingemails.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2893, 60925)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spam = np.c_[X, lingemails.spam]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training/validation chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index   spam           files  \\\n",
      "0     2000   True    spmsgb34.txt   \n",
      "1     2817  False   9-560msg1.txt   \n",
      "2     1386  False  8-1120msg1.txt   \n",
      "3     1161  False   6-245msg1.txt   \n",
      "4     2313   True     spmsgc1.txt   \n",
      "..     ...    ...             ...   \n",
      "573    293  False     9-5msg1.txt   \n",
      "574    388  False   9-745msg1.txt   \n",
      "575   1183  False   6-280msg1.txt   \n",
      "576   1515  False  9-1017msg1.txt   \n",
      "577    577   True    spmsgc97.txt   \n",
      "\n",
      "                                               message  \n",
      "0    Subject: family name history  discover your fa...  \n",
      "1    Subject: ecai-98 # 8 : accepted papers and reg...  \n",
      "2    Subject: computer - mediated conversation  = =...  \n",
      "3    Subject: language teaching lists  hi , an acqu...  \n",
      "4    Subject: total profit + 980 % in 1998  = = = =...  \n",
      "..                                                 ...  \n",
      "573  Subject: conference on research and advanced t...  \n",
      "574  Subject: languages of the world , institute of...  \n",
      "575  Subject: about e . h . tuttle ( sumary )  some...  \n",
      "576  Subject: hil phonology 4 ( hilp 4 )  call for ...  \n",
      "577  Subject: submit 600  this is not spam ; you ar...  \n",
      "\n",
      "[578 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "testing, training = train_test_split(X_spam, train_size = 0.2)\n",
    "testing_for_smoothing, training_for_smoothing = train_test_split(X_spam, train_size = 0.2)\n",
    "testing_for_smoothing_examples, training_for_smoothing_examples = train_test_split(lingemails, train_size = 0.2)\n",
    "testing_for_smoothing_examples.reset_index(inplace = True)\n",
    "print(testing_for_smoothing_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 60926)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training), len(training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([416860])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(training.T[60925]==1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the spam indicator, which is the last column(T accesses matrix by column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "isSpam = training.T[60925]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 1931],\n",
       "       [   1,  384]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCount = np.array(np.unique(isSpam, return_counts=True)).T\n",
    "spamCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 1931)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_S = spamCount[1][1]\n",
    "num_NS = spamCount[0][1]\n",
    "num_S, num_NS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the accuracy of the naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16587473002159828, 0.8341252699784018)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrcS = 384/2315\n",
    "PrcNS = 1931/2315\n",
    "PrcS, PrcNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the naive model is 83.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the unconditional (log) probability that the email is spam/non-spam, log Pr(S), andlog Pr( ̄S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.7965224139326075, -0.18137168409181997)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_PrcS = np.log(PrcS)\n",
    "log_PrcNS = np.log(PrcNS)\n",
    "log_PrcS, log_PrcNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each word w, get the (log) probability that the word is present in spam emails,log Pr(w|S), and (log) probability that the word is present in non-spam emails, log Pr(w| ̄S). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_spam = list()\n",
    "real_non_spam = list()\n",
    "\n",
    "# fetch spam and non-spam emails for training data set\n",
    "for i in range(len(training)):\n",
    "    if(training[i][-1]) == 1:\n",
    "        real_spam.append(training[i])\n",
    "    else:\n",
    "        real_non_spam.append(training[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_real_spam = list()\n",
    "testing_real_non_spam = list()\n",
    "\n",
    "# fetch spam and non-spam emails for testing data set\n",
    "for i in range(len(testing)):\n",
    "    if(testing[i][-1]) == 1:\n",
    "        testing_real_spam.append(testing[i])\n",
    "    else:\n",
    "        testing_real_non_spam.append(testing[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_spam_array = np.sum(real_spam, axis = 0)\n",
    "real_non_spam_array = np.sum(real_non_spam, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-7c1c799496e5>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  log_PrW1CS_Arr = np.log(log_PrW1CS_Arr / (num_S))\n",
      "<ipython-input-26-7c1c799496e5>:6: RuntimeWarning: divide by zero encountered in log\n",
      "  log_PrW1CNS_Arr = np.log(log_PrW1CNS_Arr / (num_NS))\n",
      "<ipython-input-26-7c1c799496e5>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  log_PrW0CS_Arr = np.log(log_PrW0CS_Arr / (num_S))\n",
      "<ipython-input-26-7c1c799496e5>:14: RuntimeWarning: divide by zero encountered in log\n",
      "  log_PrW0CNS_Arr = np.log(log_PrW0CNS_Arr / (num_NS))\n"
     ]
    }
   ],
   "source": [
    "log_PrW1CS_Arr = real_spam_array[0:-1]\n",
    "log_PrW1CS_Arr = np.log(log_PrW1CS_Arr / (num_S))\n",
    "\n",
    "# get the (W=1|S=0)\n",
    "log_PrW1CNS_Arr = real_non_spam_array[0:-1]\n",
    "log_PrW1CNS_Arr = np.log(log_PrW1CNS_Arr / (num_NS))\n",
    "\n",
    "# get the (W=0|S=1)\n",
    "log_PrW0CS_Arr = len(real_spam) - real_spam_array[0:-1]\n",
    "log_PrW0CS_Arr = np.log(log_PrW0CS_Arr / (num_S))\n",
    "\n",
    "# get the (W=0|S=0)\n",
    "log_PrW0CNS_Arr = len(real_non_spam) - real_non_spam_array[0:-1]\n",
    "log_PrW0CNS_Arr = np.log(log_PrW0CNS_Arr / (num_NS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.16315081, -1.17995793,        -inf, -5.95064255,        -inf,\n",
       "              -inf,        -inf,        -inf,        -inf,        -inf])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_PrW1CS_Arr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For both destination classes,S=1 andS=0, get thelog-likelihood that the emailbelongs to this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-d237600bcb2b>:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  PrS_Arr_regular = testing_for_regular * log_PrW1CS_Arr + testing_for_regular_switch * log_PrW0CS_Arr\n",
      "<ipython-input-29-d237600bcb2b>:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  PrNS_Arr_regular = testing_for_regular * log_PrW1CNS_Arr + testing_for_regular_switch * log_PrW0CNS_Arr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          -inf           -inf           -inf           -inf\n",
      "           -inf           -inf -1223.18539456           -inf\n",
      "           -inf           -inf]\n",
      "[         -inf          -inf          -inf          -inf          -inf\n",
      "          -inf          -inf          -inf -305.90046657 -758.29641633]\n",
      "[[481   0]\n",
      " [ 88   9]]\n",
      "0.8477508650519031\n"
     ]
    }
   ],
   "source": [
    "# exclude the last column(spam indicator)\n",
    "testing_for_regular = testing[:,:-1]\n",
    "\n",
    "# reverse 0s and 1s\n",
    "testing_for_regular_switch = (testing_for_regular - 1) * (-1)\n",
    "\n",
    "# calculate l(S=1|W) and l(S=0|W)\n",
    "PrS_Arr_regular = testing_for_regular * log_PrW1CS_Arr + testing_for_regular_switch * log_PrW0CS_Arr\n",
    "PrNS_Arr_regular = testing_for_regular * log_PrW1CNS_Arr + testing_for_regular_switch * log_PrW0CNS_Arr\n",
    "#use np.nansum() to ignore nan when summing\n",
    "PrS_Arr_sum_regular = np.nansum(PrS_Arr_regular, axis = 1) + log_PrcS \n",
    "PrNS_Arr_sum_regular = np.nansum(PrNS_Arr_regular, axis = 1) + log_PrcNS\n",
    "\n",
    "print(PrS_Arr_sum_regular[:10])\n",
    "print(PrNS_Arr_sum_regular[:10])\n",
    "\n",
    "# predict the emails\n",
    "testing_list = []\n",
    "for i in range(len(testing)):\n",
    "    testing_list.append((PrS_Arr_sum_regular[i] > PrNS_Arr_sum_regular[i]) + 0)\n",
    "\n",
    "testing_prediction = np.c_[testing, testing_list]\n",
    "\n",
    "# get the confusion matrix and accuracy score\n",
    "print(confusion_matrix(testing_prediction[:,-2], testing_prediction[:,-1]))\n",
    "\n",
    "accuracy_rate = accuracy_score(testing_prediction[:,-2], testing_prediction[:,-1])\n",
    "\n",
    "print(accuracy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we get a lot of inifities using the naive bayes approach, now we move forward to adding smoothing to get rid of the infinities that affected the result previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "log_PrW1CS_Arr_smoothing = list()\n",
    "log_PrW1CNS_Arr_smoothing = list()\n",
    "log_PrW0CNS_Arr_smoothing = list()\n",
    "log_PrW0CS_Arr_smoothing = list()\n",
    "PrNS_Arr = list()\n",
    "PrS_Arr = list()\n",
    "\n",
    "# get the email counts for each word\n",
    "# real_spam_array = np.sum(real_spam, axis = 0)\n",
    "# real_non_spam_array = np.sum(real_non_spam, axis = 0)\n",
    "\n",
    "# get the (W=1|S=1)\n",
    "log_PrW1CS_Arr_smoothing = real_spam_array[0:-1] + alpha \n",
    "log_PrW1CS_Arr_smoothing = np.log(log_PrW1CS_Arr_smoothing / (num_S + 2 * alpha))\n",
    "\n",
    "# get the (W=1|S=0)\n",
    "log_PrW1CNS_Arr_smoothing = real_non_spam_array[0:-1] + alpha\n",
    "log_PrW1CNS_Arr_smoothing = np.log(log_PrW1CNS_Arr_smoothing / (num_NS + 2 * alpha))\n",
    "\n",
    "# get the (W=0|S=1)\n",
    "log_PrW0CS_Arr_smoothing = len(real_spam) - real_spam_array[0:-1] + alpha\n",
    "log_PrW0CS_Arr_smoothing = np.log(log_PrW0CS_Arr_smoothing / (num_S + 2 * alpha))\n",
    "\n",
    "# get the (W=0|S=0)\n",
    "log_PrW0CNS_Arr_smoothing = len(real_non_spam) - real_non_spam_array[0:-1] + alpha\n",
    "log_PrW0CNS_Arr_smoothing = np.log(log_PrW0CNS_Arr_smoothing / (num_NS + 2 * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.16159358, -1.17833037, -6.64639051, -5.54777823, -6.64639051,\n",
       "       -6.64639051, -6.64639051, -6.64639051, -6.64639051, -6.64639051])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_PrW1CS_Arr_smoothing[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_alpha(alpha):\n",
    "    log_PrW1CS_Arr_smoothing = list()\n",
    "    log_PrW1CNS_Arr_smoothing = list()\n",
    "    log_PrW0CNS_Arr_smoothing = list()\n",
    "    log_PrW0CS_Arr_smoothing = list()\n",
    "    PrNS_Arr = list()\n",
    "    PrS_Arr = list()\n",
    "    \n",
    "    # get the email counts for each word\n",
    "    real_spam_array = np.sum(real_spam, axis = 0)\n",
    "    real_non_spam_array = np.sum(real_non_spam, axis = 0)\n",
    "     \n",
    "    # get the (W=1|S=1)\n",
    "    log_PrW1CS_Arr_smoothing = real_spam_array[0:-1] + alpha \n",
    "    log_PrW1CS_Arr_smoothing = np.log(log_PrW1CS_Arr_smoothing / (num_S + 2 * alpha))\n",
    "    \n",
    "    # get the (W=1|S=0)\n",
    "    log_PrW1CNS_Arr_smoothing = real_non_spam_array[0:-1] + alpha\n",
    "    log_PrW1CNS_Arr_smoothing = np.log(log_PrW1CNS_Arr_smoothing / (num_NS + 2 * alpha))\n",
    "    \n",
    "    # get the (W=0|S=1)\n",
    "    log_PrW0CS_Arr_smoothing = len(real_spam) - real_spam_array[0:-1] + alpha\n",
    "    log_PrW0CS_Arr_smoothing = np.log(log_PrW0CS_Arr_smoothing / (num_S + 2 * alpha))\n",
    "    \n",
    "    # get the (W=0|S=0)\n",
    "    log_PrW0CNS_Arr_smoothing = len(real_non_spam) - real_non_spam_array[0:-1] + alpha\n",
    "    log_PrW0CNS_Arr_smoothing = np.log(log_PrW0CNS_Arr_smoothing / (num_NS + 2 * alpha))\n",
    "\n",
    "    \n",
    "    # exclude the last column\n",
    "    testing_for_smoothing_1 = testing_for_smoothing[:,:-1]\n",
    "    \n",
    "    # reverse 0s and 1s\n",
    "    testing_for_smoothing_1_switch = (testing_for_smoothing_1 - 1) * (-1)\n",
    "    \n",
    "    # calculate l(S=1|W) and l(S=0|W)\n",
    "    PrS_Arr = testing_for_smoothing_1 * log_PrW1CS_Arr_smoothing + testing_for_smoothing_1_switch * log_PrW0CS_Arr_smoothing\n",
    "    PrNS_Arr = testing_for_smoothing_1 * log_PrW1CNS_Arr_smoothing + testing_for_smoothing_1_switch * log_PrW0CNS_Arr_smoothing\n",
    "    PrS_Arr_sum = np.sum(PrS_Arr, axis = 1) + log_PrcS\n",
    "    PrNS_Arr_sum = np.sum(PrNS_Arr, axis = 1) + log_PrcNS\n",
    "    \n",
    "    PrS_Arr_sum_by_column = np.sum(PrS_Arr, axis = 0)\n",
    "    PrNS_Arr_sum_by_column = np.sum(PrNS_Arr, axis = 0)\n",
    "    \n",
    "    spam_predictor = PrS_Arr_sum_by_column - PrNS_Arr_sum_by_column\n",
    "    non_spam_predictor = PrNS_Arr_sum_by_column - PrS_Arr_sum_by_column\n",
    "\n",
    "    # predict the emails\n",
    "    testing_list_smoothing = []\n",
    "    for i in range(len(testing_for_smoothing)):\n",
    "        testing_list_smoothing.append((PrS_Arr_sum[i] > PrNS_Arr_sum[i]) + 0)\n",
    "    \n",
    "    testing_prediction_smoothing = np.c_[testing_for_smoothing, testing_list_smoothing]\n",
    "    \n",
    "    # get the confusion matrix and accuracy score\n",
    "    print(confusion_matrix(testing_prediction_smoothing[:,-2], testing_prediction_smoothing[:,-1]))\n",
    "\n",
    "    accuracy_rate = accuracy_score(testing_prediction_smoothing[:,-2], testing_prediction_smoothing[:,-1])\n",
    "    \n",
    "    print(accuracy_rate, alpha)\n",
    "    \n",
    "    return accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[477   0]\n",
      " [  2  99]]\n",
      "0.9965397923875432 1e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9965397923875432"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_alpha(0.000001) #reached accuracy of 99.66% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best smoothing parameter α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[477   0]\n",
      " [  2  99]]\n",
      "0.9965397923875432 1e-08\n",
      "[[477   0]\n",
      " [  2  99]]\n",
      "0.9965397923875432 1e-07\n",
      "[[477   0]\n",
      " [  2  99]]\n",
      "0.9965397923875432 1e-06\n",
      "[[477   0]\n",
      " [  2  99]]\n",
      "0.9965397923875432 1e-05\n",
      "[[477   0]\n",
      " [  1 100]]\n",
      "0.9982698961937716 0.0001\n",
      "[[477   0]\n",
      " [  1 100]]\n",
      "0.9982698961937716 0.001\n",
      "[[476   1]\n",
      " [  1 100]]\n",
      "0.9965397923875432 0.01\n",
      "[[476   1]\n",
      " [  0 101]]\n",
      "0.9982698961937716 0.1\n",
      "[[477   0]\n",
      " [ 40  61]]\n",
      "0.9307958477508651 1.0\n",
      "[[477   0]\n",
      " [101   0]]\n",
      "0.8252595155709342 10.0\n"
     ]
    }
   ],
   "source": [
    "list_alpha = np.logspace(-8, 1, 10)\n",
    "accuracy_list = list()\n",
    "for i in list_alpha:\n",
    "    accuracy_list.append(different_alpha(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(list_alpha, accuracy_list, marker=\"o\")\n",
    "_ = plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best predictors are alpha=[0.001, 0.001, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best words to predict spam and non-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_words(alpha):\n",
    "    log_PrW1CS_Arr_smoothing = list()\n",
    "    log_PrW1CNS_Arr_smoothing = list()\n",
    "    log_PrW0CNS_Arr_smoothing = list()\n",
    "    log_PrW0CS_Arr_smoothing = list()\n",
    "    PrNS_Arr = list()\n",
    "    PrS_Arr = list()\n",
    "    \n",
    "    # get the email counts for each word\n",
    "    real_spam_array = np.sum(real_spam, axis = 0)\n",
    "    real_non_spam_array = np.sum(real_non_spam, axis = 0)\n",
    "     \n",
    "    # get the (W=1|S=1)\n",
    "    log_PrW1CS_Arr_smoothing = real_spam_array[0:-1] + alpha \n",
    "    log_PrW1CS_Arr_smoothing = np.log(log_PrW1CS_Arr_smoothing / (num_S + 2 * alpha))\n",
    "    \n",
    "    # get the (W=1|S=0)\n",
    "    log_PrW1CNS_Arr_smoothing = real_non_spam_array[0:-1] + alpha\n",
    "    log_PrW1CNS_Arr_smoothing = np.log(log_PrW1CNS_Arr_smoothing / (num_NS + 2 * alpha))\n",
    "    \n",
    "    # get the (W=0|S=1)\n",
    "    log_PrW0CS_Arr_smoothing = len(real_spam) - real_spam_array[0:-1] + alpha\n",
    "    log_PrW0CS_Arr_smoothing = np.log(log_PrW0CS_Arr_smoothing / (num_S + 2 * alpha))\n",
    "    \n",
    "    # get the (W=0|S=0)\n",
    "    log_PrW0CNS_Arr_smoothing = len(real_non_spam) - real_non_spam_array[0:-1] + alpha\n",
    "    log_PrW0CNS_Arr_smoothing = np.log(log_PrW0CNS_Arr_smoothing / (num_NS + 2 * alpha))\n",
    "\n",
    "    \n",
    "    # exclude the last column\n",
    "    testing_for_smoothing_1 = testing_for_smoothing[:,:-1]\n",
    "    \n",
    "    # reverse 0s and 1s\n",
    "    testing_for_smoothing_1_switch = (testing_for_smoothing_1 - 1) * (-1)\n",
    "    \n",
    "    # calculate l(S=1|W) and l(S=0|W)\n",
    "    PrS_Arr = testing_for_smoothing_1 * log_PrW1CS_Arr_smoothing + testing_for_smoothing_1_switch * log_PrW0CS_Arr_smoothing\n",
    "    PrNS_Arr = testing_for_smoothing_1 * log_PrW1CNS_Arr_smoothing + testing_for_smoothing_1_switch * log_PrW0CNS_Arr_smoothing\n",
    "    PrS_Arr_sum = np.sum(PrS_Arr, axis = 1) + log_PrcS\n",
    "    PrNS_Arr_sum = np.sum(PrNS_Arr, axis = 1) + log_PrcNS\n",
    "    \n",
    "    PrS_Arr_sum_by_column = np.sum(PrS_Arr, axis = 0)\n",
    "    PrNS_Arr_sum_by_column = np.sum(PrNS_Arr, axis = 0)\n",
    "    \n",
    "    \n",
    "    spam_predictor = PrS_Arr_sum_by_column - PrNS_Arr_sum_by_column\n",
    "    non_spam_predictor = PrNS_Arr_sum_by_column - PrS_Arr_sum_by_column\n",
    "    spam_predictor_1 = spam_predictor\n",
    "    non_spam_predictor_1 = non_spam_predictor\n",
    "    \n",
    "    print(\"top 10 words to predict non-spam:\")\n",
    "    for j in (sorted(range(len(spam_predictor)), key=lambda i: spam_predictor[i])[:10]):\n",
    "        print(vocabulary[j])\n",
    "\n",
    "    print(\"top 10 words to predict spam:\")\n",
    "    for j in (sorted(range(len(non_spam_predictor)), key=lambda i: non_spam_predictor[i])[:10]):\n",
    "        print(vocabulary[j])\n",
    "    \n",
    "    # predict the emails\n",
    "    testing_list_smoothing = []\n",
    "    for i in range(len(testing_for_smoothing)):\n",
    "        testing_list_smoothing.append((PrS_Arr_sum[i] > PrNS_Arr_sum[i]) + 0)\n",
    "    \n",
    "    testing_prediction_smoothing = np.c_[testing_for_smoothing, testing_list_smoothing]\n",
    "    \n",
    "    # get the confusion matrix and accuracy score\n",
    "    print(confusion_matrix(testing_prediction_smoothing[:,-2], testing_prediction_smoothing[:,-1]))\n",
    "\n",
    "    accuracy_rate = accuracy_score(testing_prediction_smoothing[:,-2], testing_prediction_smoothing[:,-1])\n",
    "    \n",
    "    print(accuracy_rate, alpha)\n",
    "\n",
    "    \n",
    "#     misclassified = list()\n",
    "#     for i in range(len(testing_prediction_smoothing)):\n",
    "#         if((testing_prediction_smoothing[i,-2] != testing_prediction_smoothing[i,-1])):\n",
    "#             misclassified.append(i)\n",
    "\n",
    "#     print(testing_for_smoothing_examples.message[misclassified[0]])\n",
    "#     print(\"                              \")\n",
    "#     print(testing_for_smoothing_examples.message[misclassified[1]])\n",
    "    \n",
    "    return accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 words to predict non-spam:\n",
      "linguistic\n",
      "syntax\n",
      "speakers\n",
      "theory\n",
      "deadline\n",
      "abstract\n",
      "committee\n",
      "abstracts\n",
      "structure\n",
      "workshop\n",
      "top 10 words to predict spam:\n",
      "profits\n",
      "investment\n",
      "bonus\n",
      "mlm\n",
      "intrusion\n",
      "fraction\n",
      "earning\n",
      "spam\n",
      "fingertips\n",
      "anytime\n",
      "[[477   0]\n",
      " [  2  99]]\n",
      "0.9965397923875432 1e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9965397923875432"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_words(0.000001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
